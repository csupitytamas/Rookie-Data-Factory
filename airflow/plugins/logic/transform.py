import sqlalchemy as sa
import pandas as pd
import os
from transforms.transfomations import field_mapping, group_by, order_by, flatten_grouped_data

def transform_data(pipeline_id, **kwargs):
    print(f"\n=== [TRANSFORM_DATA] pipeline_id: {pipeline_id} ===")
    ti = kwargs['ti']
    
    # 1. Adatok kinyer√©se (Extract) - Ez mindig kell
    data = ti.xcom_pull(key='extracted_data', task_ids=f"extract_data_{pipeline_id}")
    # Fallback: ha esetleg return_value-ban van
    if not data:
        data = ti.xcom_pull(task_ids=f"extract_data_{pipeline_id}")
        
    if not data:
        print("[TRANSFORM_DATA] ERROR: Nincs adat az extractb√≥l!")
        raise Exception("Nincs adat az extractb√≥l!")
    
    # 2. Pipeline Konfigur√°ci√≥ bet√∂lt√©se DB-b≈ël (Hogy l√°ssuk a custom_sql-t)
    db_url = os.getenv("DB_URL", "postgresql+psycopg2://postgres:admin123@host.docker.internal:5433/ETL")
    engine = sa.create_engine(db_url)
    
    custom_sql = None
    with engine.connect() as conn:
        # Lek√©rj√ºk a custom_sql-t √©s a transformation t√≠pust
        query = sa.text("SELECT custom_sql, transformation FROM etlconfig WHERE id = :id")
        row = conn.execute(query, {"id": pipeline_id}).mappings().first()
        if row:
            raw_sql = row.get('custom_sql')
            transform_meta = row.get('transformation')
            
            # Csak akkor vessz√ºk figyelembe, ha t√©nyleg 'advenced' m√≥dban vagyunk
            # (√©s a string nem √ºres)
            if transform_meta and transform_meta.get('type') in ['advenced', 'advanced'] and raw_sql:
                custom_sql = raw_sql

    # --- √ÅG 1: Custom SQL V√©grehajt√°s ---
    if custom_sql:
        print(f"[TRANSFORM_DATA] üöÄ Executing Custom SQL Mode:\n{custom_sql}")
        
        try:
            # Pandas DataFrame l√©trehoz√°sa
            df = pd.DataFrame(data)
            
            # Mem√≥ria SQL motor (SQLite)
            sqlite_engine = sa.create_engine('sqlite:///:memory:')
            
            # Adatok bet√∂lt√©se 'input_data' t√°bl√°ba
            df.to_sql('input_data', sqlite_engine, index=False, if_exists='replace')
            
            # SQL futtat√°sa
            result_df = pd.read_sql(custom_sql, sqlite_engine)
            
            # Eredm√©ny konvert√°l√°sa vissza list-of-dicts form√°tumba
            transformed_data = result_df.to_dict(orient='records')
            
            print(f"[TRANSFORM_DATA] SQL Result sample (first 2): {transformed_data[:2]}")
            print(f"[TRANSFORM_DATA] Rows count: {len(transformed_data)}")
            
            # Mivel SQL-t haszn√°ltunk, a mapping/sort/group l√©p√©seket kihagyjuk,
            # mert felt√©telezz√ºk, hogy az SQL mindent elint√©zett.
            ti.xcom_push(key='final_data', value=transformed_data)
            return

        except Exception as e:
            print(f"[TRANSFORM_DATA] ‚ùå SQL Execution Failed: {e}")
            raise Exception(f"Custom SQL execution error: {e}")

    # --- √ÅG 2: Hagyom√°nyos Transzform√°ci√≥ (Ha nincs SQL) ---
    print("[TRANSFORM_DATA] No Custom SQL (or source table), fetching from XCom.")

    final_columns = ti.xcom_pull(key='final_columns', task_ids=f"create_table_{pipeline_id}")
    col_rename_map = ti.xcom_pull(key='col_rename_map', task_ids=f"create_table_{pipeline_id}")
    group_by_columns = ti.xcom_pull(key='group_by_columns', task_ids=f"create_table_{pipeline_id}")
    order_by_column = ti.xcom_pull(key='order_by_column', task_ids=f"create_table_{pipeline_id}")
    order_direction = ti.xcom_pull(key='order_direction', task_ids=f"create_table_{pipeline_id}")
    field_mappings = ti.xcom_pull(key='field_mappings', task_ids=f"create_table_{pipeline_id}")

    if not final_columns:
         # Ha valami√©rt nincs create_table info (pl. k√©zi ind√≠t√°sn√°l elveszett),
         # pr√≥b√°ljuk meg az eredeti adatokat tov√°bbadni.
         print("[TRANSFORM_DATA] WARNING: Missing final_columns from XCom. Passing raw data.")
         ti.xcom_push(key='final_data', value=data)
         return

    # 1. Field mapping
    transformed = field_mapping(data, col_rename_map, final_columns, field_mappings=field_mappings)
    
    # 2. Rendez√©s
    if order_by_column:
        ordered = order_by(transformed, [order_by_column], order_direction)
    else:
        ordered = transformed

    # 3. Csoportos√≠t√°s
    if group_by_columns:
        grouped = group_by(ordered, group_by_columns)
        flattened = flatten_grouped_data(grouped)
        ti.xcom_push(key='final_data', value=flattened)
    else:
        print("[TRANSFORM_DATA] No group by applied, final data is ordered data.")
        ti.xcom_push(key='final_data', value=ordered)